{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer using LeNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baasitsharief/kaggle_digit_recognizer/blob/master/Digit_Recognizer_using_LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fr2s39YoXD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t95tC4LWsoJY",
        "colab_type": "code",
        "outputId": "1df02aa3-012d-4334-f21f-8d423b07cd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "Y_train_orig = train[\"label\"]\n",
        "X_train_orig = train.drop(labels = [\"label\"],axis = 1)\n",
        "\n",
        "del train\n",
        "\n",
        "g = sns.countplot(Y_train_orig)\n",
        "\n",
        "Y_train_orig.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAESCAYAAAAv0qjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYIuc+1O8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfBM8608sjYA",
        "colab_type": "code",
        "outputId": "b0094bc7-911d-4e71-b9a3-a5ae6901b0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#np.size((Y_train_orig.values))\n",
        "#Y_train_orig.shape\n",
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKfJWWbTvmfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_orig = X_train_orig/255\n",
        "test = test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF926S-905Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape\n",
        "X_train_orig = X_train_orig.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xfk4xDw14oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train_orig = to_categorical(Y_train_orig, num_classes = 10)\n",
        "random_seed = 2\n",
        "X_train, X_dev, Y_train, Y_dev = train_test_split(X_train_orig, Y_train_orig, test_size = 0.1,random_state = random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoKU1ciisoq2",
        "colab_type": "text"
      },
      "source": [
        "With Keras/Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHNSlM_v3Plr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DigitModel(input_shape):\n",
        "  X_input = Input(input_shape)\n",
        "  X = X_input\n",
        "  \n",
        "  #Layer 1 - Conv>BN>RELU>MaxPool\n",
        "  \n",
        "  X = Conv2D(6,(5,5),strides = (1,1), name = 'conv0', padding = 'same')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool0')(X)\n",
        "  \n",
        "  #Layer 2 - Conv>BN>RELU>MaxPool\n",
        "  \n",
        "  X = Conv2D(16,(5,5),strides = (1,1), name = 'conv1', padding = 'valid')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool1')(X)\n",
        "  \n",
        "  #FC layers with flattening\n",
        "  \n",
        "  X = Flatten()(X)\n",
        "  X = Dense(120, activation = 'relu', name = 'fc1')(X)\n",
        "  X = Dense(84, activation = 'relu', name = 'fc2')(X)\n",
        "  X = Dense(10, activation = 'softmax', name = 'preds')(X)\n",
        "  \n",
        "  #model instance creator\n",
        "  model = Model(inputs = X_input, outputs = X, name = 'DigitModel')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vengyDUtQAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize the model\n",
        "\n",
        "### START CODE HERE ### (1 line)\n",
        "input_shape = X_train.shape[1:4]\n",
        "recog = DigitModel(input_shape)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQJPQ1K7vqJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile model to configure learning process\n",
        "recog.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWC9yDkwnWv",
        "colab_type": "code",
        "outputId": "f38daefe-e1f7-4c6b-dc98-7924f9c95ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train the model\n",
        "recog.fit(x=X_train, y=Y_train, epochs = 30, batch_size = 86)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "37800/37800 [==============================] - 35s 922us/step - loss: 0.2292 - acc: 0.9285\n",
            "Epoch 2/30\n",
            "37800/37800 [==============================] - 33s 886us/step - loss: 0.0683 - acc: 0.9789\n",
            "Epoch 3/30\n",
            "37800/37800 [==============================] - 34s 892us/step - loss: 0.0466 - acc: 0.9846\n",
            "Epoch 4/30\n",
            "37800/37800 [==============================] - 34s 887us/step - loss: 0.0356 - acc: 0.9888\n",
            "Epoch 5/30\n",
            "37800/37800 [==============================] - 34s 890us/step - loss: 0.0324 - acc: 0.9896\n",
            "Epoch 6/30\n",
            "37800/37800 [==============================] - 34s 889us/step - loss: 0.0268 - acc: 0.9913\n",
            "Epoch 7/30\n",
            "37800/37800 [==============================] - 34s 893us/step - loss: 0.0236 - acc: 0.9923\n",
            "Epoch 8/30\n",
            "37800/37800 [==============================] - 34s 892us/step - loss: 0.0204 - acc: 0.9931\n",
            "Epoch 9/30\n",
            "37800/37800 [==============================] - 33s 886us/step - loss: 0.0177 - acc: 0.9945\n",
            "Epoch 10/30\n",
            "37800/37800 [==============================] - 34s 892us/step - loss: 0.0145 - acc: 0.9951\n",
            "Epoch 11/30\n",
            "37800/37800 [==============================] - 34s 888us/step - loss: 0.0156 - acc: 0.9943\n",
            "Epoch 12/30\n",
            "37800/37800 [==============================] - 34s 888us/step - loss: 0.0118 - acc: 0.9962\n",
            "Epoch 13/30\n",
            "37800/37800 [==============================] - 34s 890us/step - loss: 0.0110 - acc: 0.9961\n",
            "Epoch 14/30\n",
            "37800/37800 [==============================] - 34s 888us/step - loss: 0.0121 - acc: 0.9958\n",
            "Epoch 15/30\n",
            "37800/37800 [==============================] - 33s 883us/step - loss: 0.0089 - acc: 0.9970\n",
            "Epoch 16/30\n",
            "37800/37800 [==============================] - 33s 884us/step - loss: 0.0080 - acc: 0.9974\n",
            "Epoch 17/30\n",
            "37800/37800 [==============================] - 34s 894us/step - loss: 0.0097 - acc: 0.9966\n",
            "Epoch 18/30\n",
            "37800/37800 [==============================] - 34s 889us/step - loss: 0.0109 - acc: 0.9963\n",
            "Epoch 19/30\n",
            "37800/37800 [==============================] - 34s 894us/step - loss: 0.0083 - acc: 0.9970\n",
            "Epoch 20/30\n",
            "37800/37800 [==============================] - 34s 891us/step - loss: 0.0064 - acc: 0.9979\n",
            "Epoch 21/30\n",
            "37800/37800 [==============================] - 34s 893us/step - loss: 0.0073 - acc: 0.9974\n",
            "Epoch 22/30\n",
            "37800/37800 [==============================] - 34s 887us/step - loss: 0.0067 - acc: 0.9977\n",
            "Epoch 23/30\n",
            "37800/37800 [==============================] - 34s 887us/step - loss: 0.0037 - acc: 0.9986\n",
            "Epoch 24/30\n",
            "37800/37800 [==============================] - 34s 890us/step - loss: 0.0070 - acc: 0.9975\n",
            "Epoch 25/30\n",
            "37800/37800 [==============================] - 34s 887us/step - loss: 0.0048 - acc: 0.9983\n",
            "Epoch 26/30\n",
            "37800/37800 [==============================] - 34s 897us/step - loss: 9.7698e-04 - acc: 0.9997\n",
            "Epoch 27/30\n",
            "37800/37800 [==============================] - 34s 889us/step - loss: 0.0092 - acc: 0.9968\n",
            "Epoch 28/30\n",
            "37800/37800 [==============================] - 34s 893us/step - loss: 0.0082 - acc: 0.9971\n",
            "Epoch 29/30\n",
            "37800/37800 [==============================] - 34s 888us/step - loss: 0.0028 - acc: 0.9990\n",
            "Epoch 30/30\n",
            "37800/37800 [==============================] - 34s 889us/step - loss: 0.0051 - acc: 0.9985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8648a87b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf2VlibNy8H5",
        "colab_type": "code",
        "outputId": "d0b01cb7-a83c-4a39-e406-26e0b053eddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "preds = recog.evaluate(x = X_dev, y = Y_dev)\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4200/4200 [==============================] - 2s 380us/step\n",
            "\n",
            "Loss = 0.11258045457626287\n",
            "Test Accuracy = 0.9785714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hco2saqp89wm",
        "colab_type": "code",
        "outputId": "ed9d345a-a0c2-475e-917d-53be1846d51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_test_set = recog.predict(test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        2\n",
            "1        0\n",
            "2        9\n",
            "3        9\n",
            "4        3\n",
            "5        7\n",
            "6        0\n",
            "7        3\n",
            "8        0\n",
            "9        3\n",
            "10       5\n",
            "11       7\n",
            "12       4\n",
            "13       0\n",
            "14       4\n",
            "15       3\n",
            "16       3\n",
            "17       1\n",
            "18       9\n",
            "19       0\n",
            "20       9\n",
            "21       1\n",
            "22       1\n",
            "23       5\n",
            "24       7\n",
            "25       4\n",
            "26       2\n",
            "27       7\n",
            "28       4\n",
            "29       7\n",
            "        ..\n",
            "27970    5\n",
            "27971    0\n",
            "27972    4\n",
            "27973    8\n",
            "27974    0\n",
            "27975    3\n",
            "27976    6\n",
            "27977    0\n",
            "27978    1\n",
            "27979    9\n",
            "27980    3\n",
            "27981    1\n",
            "27982    1\n",
            "27983    0\n",
            "27984    4\n",
            "27985    5\n",
            "27986    2\n",
            "27987    2\n",
            "27988    9\n",
            "27989    6\n",
            "27990    7\n",
            "27991    6\n",
            "27992    7\n",
            "27993    9\n",
            "27994    7\n",
            "27995    9\n",
            "27996    7\n",
            "27997    3\n",
            "27998    9\n",
            "27999    2\n",
            "Name: Label, Length: 28000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k-RZUbr9Ews",
        "colab_type": "code",
        "outputId": "a5c933d6-03fd-4543-cdcd-6539b8680447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Getting the required desired matrix from max_indices\n",
        "results = np.argmax(y_test_set,axis = 1)\n",
        "#print(results)\n",
        "\n",
        "#Creating the submission Dataframe\n",
        "result = pd.DataFrame({'Label' : results })\n",
        "result_id = pd.DataFrame({'ImageId' : range(1,28001)})\n",
        "#print(result_id)\n",
        "result = pd.concat([result_id,result], axis = 1)\n",
        "#print(result)\n",
        "\n",
        "#Saving into a CSV file\n",
        "result.to_csv(\"submission.csv\", index = False)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       ImageId  Label\n",
            "0            1      2\n",
            "1            2      0\n",
            "2            3      9\n",
            "3            4      9\n",
            "4            5      3\n",
            "5            6      7\n",
            "6            7      0\n",
            "7            8      3\n",
            "8            9      0\n",
            "9           10      3\n",
            "10          11      5\n",
            "11          12      7\n",
            "12          13      4\n",
            "13          14      0\n",
            "14          15      4\n",
            "15          16      3\n",
            "16          17      3\n",
            "17          18      1\n",
            "18          19      9\n",
            "19          20      0\n",
            "20          21      9\n",
            "21          22      1\n",
            "22          23      1\n",
            "23          24      5\n",
            "24          25      7\n",
            "25          26      4\n",
            "26          27      2\n",
            "27          28      7\n",
            "28          29      4\n",
            "29          30      7\n",
            "...        ...    ...\n",
            "27970    27971      5\n",
            "27971    27972      0\n",
            "27972    27973      4\n",
            "27973    27974      8\n",
            "27974    27975      0\n",
            "27975    27976      3\n",
            "27976    27977      6\n",
            "27977    27978      0\n",
            "27978    27979      1\n",
            "27979    27980      9\n",
            "27980    27981      3\n",
            "27981    27982      1\n",
            "27982    27983      1\n",
            "27983    27984      0\n",
            "27984    27985      4\n",
            "27985    27986      5\n",
            "27986    27987      2\n",
            "27987    27988      2\n",
            "27988    27989      9\n",
            "27989    27990      6\n",
            "27990    27991      7\n",
            "27991    27992      6\n",
            "27992    27993      7\n",
            "27993    27994      9\n",
            "27994    27995      7\n",
            "27995    27996      9\n",
            "27996    27997      7\n",
            "27997    27998      3\n",
            "27998    27999      9\n",
            "27999    28000      2\n",
            "\n",
            "[28000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2CgsF1d9sgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
